#!/usr/bin/env python3
"""
Real-time WhatsApp Drop Number Monitor
Continuously monitors the Lawley Activation 3 group for new drop numbers
and automatically syncs them to Neon database.

Usage: uv run python realtime_drop_monitor.py [--interval SECONDS] [--dry-run]
"""

import argparse
import re
import time
import sqlite3
import psycopg2
from datetime import datetime, timedelta
from typing import Set, List, Dict, Optional
import logging
import os
import signal
import sys
import json

# Configuration
LAWLEY_GROUP_JID = '120363418298130331@g.us'
MESSAGES_DB_PATH = '../whatsapp-bridge/store/messages.db'
NEON_DB_URL = "postgresql://neondb_owner:npg_RIgDxzo4St6d@ep-damp-credit-a857vku0-pooler.eastus2.azure.neon.tech/neondb?sslmode=require&channel_binding=require"
DROP_PATTERN = r'DR\d+'

# Global variables for graceful shutdown
running = True
monitor_start_time = datetime.now()
STATE_FILE = 'monitor_state.json'

def setup_logging():
    """Set up logging configuration."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('realtime_monitor.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

def signal_handler(signum, frame):
    """Handle graceful shutdown."""
    global running
    logger.info(f"Received signal {signum}. Shutting down gracefully...")
    running = False

def load_monitor_state() -> datetime:
    """Load the last check timestamp from state file."""
    try:
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, 'r') as f:
                state = json.load(f)
                last_check = datetime.fromisoformat(state['last_check_time'])
                logger.info(f"üìÇ Loaded last check time from state: {last_check}")
                return last_check
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Could not load state file: {e}")
    
    # Default to 1 hour ago to avoid processing too many old messages on first run
    default_time = datetime.now() - timedelta(hours=1)
    logger.info(f"üïê Using default start time (1 hour ago): {default_time}")
    return default_time

def save_monitor_state(last_check_time: datetime, processed_ids: Set[str]):
    """Save the current monitor state to file."""
    try:
        # Keep only last 1000 IDs to prevent file from growing too large
        processed_list = list(processed_ids)
        if len(processed_list) > 1000:
            processed_list = processed_list[-1000:]
        
        state = {
            'last_check_time': last_check_time.isoformat(),
            'processed_message_ids': processed_list,
            'saved_at': datetime.now().isoformat()
        }
        with open(STATE_FILE, 'w') as f:
            json.dump(state, f, indent=2)
        logger.debug(f"üíæ State saved: last_check={last_check_time}")
    except Exception as e:
        logger.error(f"‚ùå Could not save state: {e}")

def load_processed_message_ids() -> Set[str]:
    """Load previously processed message IDs from state file."""
    try:
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, 'r') as f:
                state = json.load(f)
                processed_ids = set(state.get('processed_message_ids', []))
                logger.info(f"üìÇ Loaded {len(processed_ids)} processed message IDs")
                return processed_ids
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Could not load processed IDs: {e}")
    
    return set()

def get_latest_messages_from_sqlite(since_timestamp: datetime) -> List[Dict]:
    """Get latest messages from WhatsApp SQLite database."""
    try:
        conn = sqlite3.connect(MESSAGES_DB_PATH)
        cursor = conn.cursor()
        
        # Get messages from Lawley group since the given timestamp
        cursor.execute("""
            SELECT id, content, sender, timestamp, is_from_me
            FROM messages 
            WHERE chat_jid = ? AND timestamp > ? AND content != ''
            ORDER BY timestamp ASC
        """, (LAWLEY_GROUP_JID, since_timestamp.isoformat()))
        
        messages = []
        for row in cursor.fetchall():
            messages.append({
                'id': row[0],
                'content': row[1],
                'sender': row[2],
                'timestamp': datetime.fromisoformat(row[3]),
                'is_from_me': bool(row[4])
            })
        
        cursor.close()
        conn.close()
        return messages
        
    except Exception as e:
        logger.error(f"Error reading from SQLite: {e}")
        return []

def extract_drop_numbers_from_messages(messages: List[Dict]) -> List[Dict]:
    """Extract drop numbers from messages."""
    found_drops = []
    
    for msg in messages:
        content = msg['content']
        drops_in_message = re.findall(DROP_PATTERN, content, re.IGNORECASE)
        
        for drop in drops_in_message:
            drop_upper = drop.upper()
            
            # Create contractor name from sender
            sender = msg['sender']
            contractor_name = f'WhatsApp-{sender[:20]}...' if len(sender) > 20 else f'WhatsApp-{sender}'
            
            found_drops.append({
                'drop_number': drop_upper,
                'message_id': msg['id'],
                'sender': sender,
                'contractor_name': contractor_name,
                'timestamp': msg['timestamp'],
                'message_content': content,
                'address': 'Extracted from WhatsApp Lawley Activation 3 group'
            })
    
    return found_drops

def get_existing_drop_numbers_from_neon() -> Set[str]:
    """Get existing DR drop numbers from Neon database."""
    try:
        conn = psycopg2.connect(NEON_DB_URL)
        cursor = conn.cursor()
        cursor.execute("SELECT drop_number FROM installations WHERE drop_number LIKE 'DR%'")
        existing = {row[0] for row in cursor.fetchall()}
        cursor.close()
        conn.close()
        return existing
    except Exception as e:
        logger.error(f"Error reading from Neon database: {e}")
        return set()

def create_qa_photo_review(drop_number: str, contractor_name: str, dry_run: bool = False) -> bool:
    """Create a QA photo review entry for the drop number."""
    if dry_run:
        logger.info(f"üîç DRY RUN: Would create QA photo review for {drop_number}")
        return True
    
    try:
        conn = psycopg2.connect(NEON_DB_URL)
        cursor = conn.cursor()
        
        # Check if QA review already exists for today
        cursor.execute("""
            SELECT id FROM qa_photo_reviews 
            WHERE drop_number = %s AND review_date = CURRENT_DATE
        """, (drop_number,))
        
        if cursor.fetchone():
            logger.debug(f"QA photo review already exists for {drop_number} today")
            cursor.close()
            conn.close()
            return True
        
        # Extract user name from contractor (remove WhatsApp- prefix)
        user_name = contractor_name.replace('WhatsApp-', '')[:20] if contractor_name.startswith('WhatsApp-') else contractor_name[:20]
        
        # Insert QA photo review with all steps defaulting to false
        insert_query = """
        INSERT INTO qa_photo_reviews (
            drop_number, 
            review_date,
            user_name,
            step_01_property_frontage, step_02_location_before_install,
            step_03_outside_cable_span, step_04_home_entry_outside,
            step_05_home_entry_inside, step_06_fibre_entry_to_ont,
            step_07_patched_labelled_drop, step_08_work_area_completion,
            step_09_ont_barcode_scan, step_10_ups_serial_number,
            step_11_powermeter_reading, step_12_powermeter_at_ont,
            step_13_active_broadband_light, step_14_customer_signature,
            outstanding_photos_loaded_to_1map,
            comment
        ) VALUES (
            %s, CURRENT_DATE, %s,
            FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,
            FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,
            FALSE,
            %s
        )
        """
        
        comment = f"Auto-created from WhatsApp drop detection on {datetime.now().isoformat()}"
        
        cursor.execute(insert_query, (
            drop_number,
            user_name,
            comment
        ))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        logger.info(f"üìã Created QA photo review for {drop_number} (user: {user_name})")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error creating QA photo review for {drop_number}: {e}")
        return False

def insert_drop_numbers_to_neon(drop_data: List[Dict], dry_run: bool = False) -> int:
    """Insert new drop numbers into Neon database and create QA photo reviews."""
    if not drop_data:
        return 0
    
    if dry_run:
        logger.info(f"üîç DRY RUN: Would insert {len(drop_data)} drop numbers:")
        for drop in drop_data:
            logger.info(f"   ‚Ä¢ {drop['drop_number']} from {drop['contractor_name']}")
            logger.info(f"   ‚Ä¢ Would create QA photo review for {drop['drop_number']}")
        return len(drop_data)
    
    try:
        conn = psycopg2.connect(NEON_DB_URL)
        cursor = conn.cursor()
        
        insert_query = """
        INSERT INTO installations (
            drop_number, 
            contractor_name, 
            address, 
            status, 
            agent_notes
        ) VALUES (%s, %s, %s, %s, %s)
        """
        
        inserted_count = 0
        for drop_info in drop_data:
            try:
                cursor.execute(insert_query, (
                    drop_info['drop_number'],
                    drop_info['contractor_name'],
                    drop_info['address'],
                    'submitted',
                    f"Auto-imported from WhatsApp on {datetime.now().isoformat()} - "
                    f"Original timestamp: {drop_info['timestamp']} - "
                    f"Message: {drop_info['message_content'][:100]}..."
                ))
                inserted_count += 1
                logger.info(f"‚úÖ Inserted: {drop_info['drop_number']} from {drop_info['sender']}")
                
                # Create QA photo review for this drop
                create_qa_photo_review(
                    drop_info['drop_number'], 
                    drop_info['contractor_name'], 
                    dry_run=False
                )
                
            except Exception as e:
                logger.error(f"‚ùå Error inserting {drop_info['drop_number']}: {e}")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        if inserted_count > 0:
            logger.info(f"üéâ Successfully inserted {inserted_count} new drop numbers!")
        
        return inserted_count
        
    except Exception as e:
        logger.error(f"‚ùå Database error during insertion: {e}")
        return 0

def send_notification(drop_numbers: List[str], method: str = "log"):
    """Send notification about new drop numbers (placeholder for future implementation)."""
    message = f"üö® NEW DROP NUMBERS DETECTED: {', '.join(drop_numbers)}"
    
    if method == "log":
        logger.info(f"üì¢ NOTIFICATION: {message}")
    
    # Future implementations could include:
    # - Email notifications
    # - Slack/Discord webhooks  
    # - WhatsApp messages to admin
    # - Desktop notifications

def monitor_and_sync(check_interval: int = 30, dry_run: bool = False):
    """Main monitoring loop."""
    global running, monitor_start_time
    
    logger.info("üöÄ Starting Real-time Drop Number Monitor...")
    logger.info(f"{'üìã DRY RUN MODE' if dry_run else 'üíæ LIVE MODE'}")
    logger.info(f"‚è∞ Check interval: {check_interval} seconds")
    logger.info(f"üëÄ Monitoring group: {LAWLEY_GROUP_JID}")
    logger.info("=" * 70)
    
    # Load persistent state
    last_check_time = load_monitor_state()
    processed_message_ids = load_processed_message_ids()
    
    while running:
        try:
            # Get new messages since last check
            new_messages = get_latest_messages_from_sqlite(last_check_time)
            
            if new_messages:
                logger.info(f"üì± Found {len(new_messages)} new messages since {last_check_time}")
                
                # Filter out messages we've already processed
                unprocessed_messages = [
                    msg for msg in new_messages 
                    if msg['id'] not in processed_message_ids
                ]
                
                if unprocessed_messages:
                    # Extract drop numbers from new messages
                    new_drops = extract_drop_numbers_from_messages(unprocessed_messages)
                    
                    if new_drops:
                        logger.info(f"üéØ Found {len(new_drops)} drop numbers in new messages:")
                        for drop in new_drops:
                            logger.info(f"   ‚Ä¢ {drop['drop_number']} - {drop['timestamp']} - {drop['sender']}")
                        
                        # Check which are actually new (not in Neon database)
                        existing_in_neon = get_existing_drop_numbers_from_neon()
                        truly_new_drops = [
                            drop for drop in new_drops 
                            if drop['drop_number'] not in existing_in_neon
                        ]
                        
                        if truly_new_drops:
                            logger.info(f"üÜï {len(truly_new_drops)} drop numbers are new to database")
                            
                            # Send notification
                            new_drop_numbers = [drop['drop_number'] for drop in truly_new_drops]
                            send_notification(new_drop_numbers)
                            
                            # Insert into database
                            inserted = insert_drop_numbers_to_neon(truly_new_drops, dry_run)
                            
                            if inserted > 0:
                                logger.info(f"‚úÖ Successfully synced {inserted} new drop numbers to database!")
                        else:
                            logger.info("‚ÑπÔ∏è  All found drop numbers already exist in database")
                    else:
                        logger.debug("No drop numbers found in new messages")
                    
                    # Mark messages as processed
                    for msg in unprocessed_messages:
                        processed_message_ids.add(msg['id'])
                else:
                    logger.debug("No unprocessed messages found")
            else:
                logger.debug(f"No new messages since {last_check_time}")
            
            # Update last check time to the most recent message timestamp or now
            if new_messages:
                last_check_time = max(msg['timestamp'] for msg in new_messages)
            else:
                last_check_time = datetime.now()
            
            # Save state after processing
            save_monitor_state(last_check_time, processed_message_ids)
            
            # Wait before next check
            if running:
                time.sleep(check_interval)
                
        except KeyboardInterrupt:
            logger.info("‚ö†Ô∏è  Received keyboard interrupt. Shutting down...")
            break
        except Exception as e:
            logger.error(f"‚ùå Error in monitoring loop: {e}")
            logger.info(f"‚è∞ Waiting {check_interval} seconds before retry...")
            time.sleep(check_interval)
    
    logger.info("üõë Monitor stopped.")
    
    # Print summary
    runtime = datetime.now() - monitor_start_time
    logger.info(f"üìä Monitor ran for {runtime}")
    logger.info("üëã Goodbye!")

def main():
    global logger
    
    # Set up logging
    logger = setup_logging()
    
    # Set up signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    parser = argparse.ArgumentParser(description='Real-time WhatsApp drop number monitor')
    parser.add_argument('--interval', type=int, default=30, 
                       help='Check interval in seconds (default: 30)')
    parser.add_argument('--dry-run', action='store_true', 
                       help='Preview mode - don\'t actually insert into database')
    
    args = parser.parse_args()
    
    # Validate interval
    if args.interval < 5:
        logger.warning("‚ö†Ô∏è  Minimum interval is 5 seconds. Setting to 5.")
        args.interval = 5
    
    # Check if WhatsApp database exists
    if not os.path.exists(MESSAGES_DB_PATH):
        logger.error(f"‚ùå WhatsApp database not found at {MESSAGES_DB_PATH}")
        logger.error("   Make sure the WhatsApp bridge is running and has created the database.")
        sys.exit(1)
    
    # Test connections
    logger.info("üîß Testing database connections...")
    
    # Test SQLite connection
    try:
        conn = sqlite3.connect(MESSAGES_DB_PATH)
        conn.close()
        logger.info("‚úÖ SQLite connection OK")
    except Exception as e:
        logger.error(f"‚ùå SQLite connection failed: {e}")
        sys.exit(1)
    
    # Test Neon connection
    try:
        conn = psycopg2.connect(NEON_DB_URL)
        conn.close()
        logger.info("‚úÖ Neon database connection OK")
    except Exception as e:
        logger.error(f"‚ùå Neon database connection failed: {e}")
        sys.exit(1)
    
    # Start monitoring
    monitor_and_sync(args.interval, args.dry_run)

if __name__ == "__main__":
    main()